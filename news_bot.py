import requests
import datetime
import os
import urllib.parse
import xml.etree.ElementTree as ET
import time
import re
import difflib
from email.utils import parsedate_to_datetime

# ==========================================
# 1. ì„¤ì •
# ==========================================
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
CHAT_ID = os.environ.get("CHAT_ID")

# ==========================================
# 2. ë‚ ì§œ ê³„ì‚° (ì–´ì œ 00:00 ~ 23:59)
# ==========================================
def get_yesterday_range():
    now_kst = datetime.datetime.utcnow() + datetime.timedelta(hours=9)
    yesterday = now_kst - datetime.timedelta(days=1)
    return yesterday.date()

# ==========================================
# 3. í…”ë ˆê·¸ë¨ ì „ì†¡
# ==========================================
def send_telegram_message(text):
    if not text.strip(): return
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": True
    }
    try:
        requests.post(url, json=payload)
        time.sleep(0.5)
    except Exception as e:
        print(f"âŒ ì—°ê²° ì—ëŸ¬: {e}")

# ==========================================
# 4. ì„¤ì • ì½ê¸° (ì•Œë¦¼ ë©”ì‹œì§€ ì‚­ì œë¨)
# ==========================================
def get_settings_from_pin():
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/getChat?chat_id={CHAT_ID}"
    stocks = ["ì‚¼ì„±ì „ì"]
    filter_keywords = []
    
    try:
        res = requests.get(url).json()
        if "result" in res and "pinned_message" in res["result"]:
            raw_text = res["result"]["pinned_message"]["text"]
            lines = raw_text.split('\n')
            
            temp_stocks = []
            temp_keywords = []
            current_mode = None

            for line in lines:
                line = line.strip()
                if not line: continue 
                
                if "ì¢…ëª©" in line and ":" in line:
                    current_mode = "stock"
                    content = line.split(":", 1)[1]
                    temp_stocks.extend(content.split(","))
                    continue
                elif "í‚¤ì›Œë“œ" in line and ":" in line:
                    current_mode = "keyword"
                    content = line.split(":", 1)[1]
                    temp_keywords.extend(content.split(","))
                    continue
                
                if current_mode == "stock": temp_stocks.extend(line.split(","))
                elif current_mode == "keyword": temp_keywords.extend(line.split(","))

            stocks = [s.strip() for s in temp_stocks if s.strip()]
            filter_keywords = [k.strip() for k in temp_keywords if k.strip()]
            
            # [ì‚­ì œë¨] "ê²€ìƒ‰ ì‹œì‘" ì•Œë¦¼ ë©”ì‹œì§€ ë¶€ë¶„ ì œê±°
            # ì¡°ìš©íˆ ì„¤ì •ê°’ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
            return stocks, filter_keywords

    except Exception as e:
        # ì—ëŸ¬ ë‚  ë•Œë§Œ ì•Œë ¤ì¤Œ
        send_telegram_message(f"âš ï¸ ì„¤ì • ì½ê¸° ì‹¤íŒ¨: {e}")
        
    return stocks, filter_keywords

# ==========================================
# 5. ìœ ì‚¬ë„ ê²€ì‚¬ ë° í•„í„°ë§
# ==========================================
def clean_title_for_compare(title):
    title = re.sub(r'\[.*?\]', '', title) 
    title = re.sub(r'\(.*?\)', '', title)
    title = re.sub(r'[^\w\s]', '', title)
    return title.strip().replace(" ", "")

def is_similar_news(new_title, existing_titles):
    target = clean_title_for_compare(new_title)
    for exist in existing_titles:
        compared = clean_title_for_compare(exist)
        similarity = difflib.SequenceMatcher(None, target, compared).ratio()
        if similarity > 0.6: return True
    return False

# ==========================================
# 6. ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ë¥˜ (í˜ìŠ¤í‹°ë²Œ ì°¨ë‹¨ ì¶”ê°€)
# ==========================================
def fetch_and_classify_news(stocks, filter_keywords):
    all_keyword_news = {} 
    all_normal_news = {} 
    
    target_date = get_yesterday_range()
    
    # â˜… ë…¸ì´ì¦ˆ í•„í„° ë¦¬ìŠ¤íŠ¸
    NOISE_WORDS = [
        # 1. ì“¸ëª¨ì—†ëŠ” ì¹´í…Œê³ ë¦¬
        "í¬í† ", "í™”ë³´", "ì‚¬ì§„", "ìŠ¤í¬ì¸ ", "ì—°ì˜ˆ", "ë¶€ê³ ", "ì¸ì‚¬", "ë™ì˜ìƒ", "ì˜¤ëŠ˜ì˜", "ë¯¸ë¦¬ë³´ëŠ”",
        # 2. ìŠ¤í¬ì¸  ê´€ë ¨
        "ì•¼êµ¬", "ì¶•êµ¬", "ë†êµ¬", "ë°°êµ¬", "ê³¨í”„", "ì˜¬ë¦¼í”½", "ì›”ë“œì»µ", "ì„ ìˆ˜", "ê²½ê¸°", "ë¦¬ê·¸", "ìš°ìŠ¹", "ê°ë…", "ì‹œêµ¬", 
        "ì—°ìŠ¹", "ì—°íŒ¨",
        # 3. ì‚¬íšŒí™œë™/CSR/ìˆ˜ìƒ/ì¶•ì œ ê´€ë ¨
        "ì‚¬íšŒê³µí—Œ", "ë´‰ì‚¬", "ë‚˜ëˆ”", "ê¸°ë¶€", "ì„±ê¸ˆ", "ìº í˜ì¸", "í›„ì›", "ì¥í•™", "ì§€ì›ì‚¬ì—…", "CSR", "í”Œë¡œê¹…", "ì—°íƒ„",
        "ìˆ˜ìƒ", "ëŒ€ìƒ", "í‘œì°½", "ì„ ì •", "í˜ìŠ¤í‹°ë²Œ", "ë°•ëŒíšŒ", "ì „ì‹œíšŒ", # [NEW] í˜ìŠ¤í‹°ë²Œ, ë°•ëŒíšŒ ì¶”ê°€ë¨
        # 4. ë§ˆì¼€íŒ…/ì´ë²¤íŠ¸/í˜œíƒ/ë¡ ì¹­ ê´€ë ¨
        "ì´ë²¤íŠ¸", "í”„ë¡œëª¨ì…˜", "í˜œíƒ", "í• ì¸", "ì ë¦½", "ê²½í’ˆ", "ì‚¬ì€í’ˆ", "íŠ¹ê°€", "ê¸°íšì „", "ì¿ í°", "ì²´í—˜ë‹¨", "ì˜¤í”ˆëŸ°", "í˜ì´ë°±", "ì¶œì‹œê¸°ë…",
        "ë¡ ì¹­", "ëŸ°ì¹­", "ì˜¤í”ˆ", "ê°œì¥", "ì…ì "
    ]

    for i, stock in enumerate(stocks):
        if i > 0: time.sleep(1.5)
        
        encoded_keyword = urllib.parse.quote(stock)
        url = f"https://news.google.com/rss/search?q={encoded_keyword}+when:2d&hl=ko&gl=KR&ceid=KR:ko"
        
        try:
            res = requests.get(url, timeout=10)
            if res.status_code != 200: continue
            
            try:
                root = ET.fromstring(res.content)
            except: continue

            items = root.findall(".//item")
            stock_normal_items = []
            stock_keyword_items = []
            seen_titles = []

            for item in items:
                try:
                    pub_date_str = item.find("pubDate").text
                    article_dt_utc = parsedate_to_datetime(pub_date_str)
                    article_dt_kst = article_dt_utc + datetime.timedelta(hours=9)
                    if article_dt_kst.date() != target_date: continue 
                except: continue

                title = item.find("title").text.strip()
                link = item.find("link").text
                
                # --- [ê°•ë ¥í•œ í•„í„°ë§] ---
                if any(noise in title for noise in NOISE_WORDS): continue
                if stock not in title: continue
                if is_similar_news(title, seen_titles): continue
                
                seen_titles.append(title)

                # --- [ë¶„ë¥˜] ---
                is_matched = False
                matched_key = ""
                if filter_keywords:
                    for key in filter_keywords:
                        if key in title:
                            is_matched = True
                            matched_key = key
                            break
                
                formatted_link = f"<a href='{link}'>{title}</a>"

                if is_matched:
                    stock_keyword_items.append(f"({matched_key}) {formatted_link}")
                else:
                    stock_normal_items.append(formatted_link)
            
            if stock_keyword_items:
                all_keyword_news[stock] = stock_keyword_items
                
            if stock_normal_items:
                all_normal_news[stock] = stock_normal_items[:3]
                
        except Exception as e:
            print(f"[{stock}] ì—ëŸ¬: {e}")
            continue
            
    return all_keyword_news, all_normal_news

# ==========================================
# 7. ìŠ¤ë§ˆíŠ¸ ë²„í¼ ì „ì†¡
# ==========================================
def smart_send(header, lines):
    if not lines: return
    MAX_LENGTH = 3000
    current_buffer = header + "\n\n"
    
    for line in lines:
        if len(current_buffer) + len(line) > MAX_LENGTH:
            send_telegram_message(current_buffer)
            current_buffer = "" 
        current_buffer += line + "\n"
    
    if current_buffer.strip():
        send_telegram_message(current_buffer)

# ==========================================
# 8. ë©”ì¸ ì‹¤í–‰
# ==========================================
if __name__ == "__main__":
    if not TELEGRAM_TOKEN or not CHAT_ID: exit(1)

    stocks, filters = get_settings_from_pin()
    keyword_news, normal_news = fetch_and_classify_news(stocks, filters)
    yesterday_str = get_yesterday_range().strftime("%Y-%m-%d")
    
    # [1] í•µì‹¬ ë¦¬í¬íŠ¸
    if keyword_news:
        header = f"ğŸ”¥ <b>í•µì‹¬ ìš”ì•½ ë¦¬í¬íŠ¸ ({yesterday_str})</b>"
        flat_keyword_list = []
        for stock, items in keyword_news.items():
            flat_keyword_list.append(f"âœ… <b>[{stock}]</b>")
            for item in items: flat_keyword_list.append(f"â”” {item}")
            flat_keyword_list.append("")
        smart_send(header, flat_keyword_list)
    else:
        # ë‰´ìŠ¤ ì—†ìœ¼ë©´ ì¡°ìš©íˆ ì¢…ë£Œ (ì•„ë¬´ ë©”ì‹œì§€ë„ ì•ˆ ë³´ëƒ„)
        pass
    
    # [2] ì¼ë°˜ ë‰´ìŠ¤
    if normal_news:
        header = f"ğŸ“° <b>ì¼ë°˜ ë‰´ìŠ¤ (Top 3)</b>"
        flat_normal_list = []
        for stock, items in normal_news.items():
            flat_normal_list.append(f"ğŸ”¹ <b>{stock}</b>")
            for item in items: flat_normal_list.append(f"- {item}")
            flat_normal_list.append("")
        smart_send(header, flat_normal_list)
    else:
        # ë‰´ìŠ¤ ì—†ìœ¼ë©´ ì¡°ìš©íˆ ì¢…ë£Œ
        pass
